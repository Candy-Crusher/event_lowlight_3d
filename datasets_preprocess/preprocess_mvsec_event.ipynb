{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class EventRepresentation:\n",
    "    def convert(self, x: torch.Tensor, y: torch.Tensor, pol: torch.Tensor, time: torch.Tensor):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class VoxelGrid(EventRepresentation):\n",
    "    def __init__(self, channels: int, height: int, width: int, normalize: bool):\n",
    "        self.voxel_grid = torch.zeros((channels, height, width), dtype=torch.float, requires_grad=False)\n",
    "        self.nb_channels = channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def convert(self, x: torch.Tensor, y: torch.Tensor, pol: torch.Tensor, time: torch.Tensor):\n",
    "        assert x.shape == y.shape == pol.shape == time.shape\n",
    "        assert x.ndim == 1\n",
    "\n",
    "        C, H, W = self.voxel_grid.shape\n",
    "        with torch.no_grad():\n",
    "            self.voxel_grid = self.voxel_grid.to(pol.device)\n",
    "            voxel_grid = self.voxel_grid.clone()\n",
    "\n",
    "            t_norm = time\n",
    "            t_norm = (C - 1) * (t_norm-t_norm[0]) / (t_norm[-1]-t_norm[0])\n",
    "\n",
    "            x0 = x.int()\n",
    "            y0 = y.int()\n",
    "            t0 = t_norm.int()\n",
    "\n",
    "            if pol.min() == 0:\n",
    "                value = 2*pol-1\n",
    "            else:\n",
    "                value = pol\n",
    "\n",
    "            for xlim in [x0,x0+1]:\n",
    "                for ylim in [y0,y0+1]:\n",
    "                    for tlim in [t0,t0+1]:\n",
    "\n",
    "                        mask = (xlim < W) & (xlim >= 0) & (ylim < H) & (ylim >= 0) & (tlim >= 0) & (tlim < self.nb_channels)\n",
    "                        interp_weights = value * (1 - (xlim-x).abs()) * (1 - (ylim-y).abs()) * (1 - (tlim - t_norm).abs())\n",
    "\n",
    "                        index = H * W * tlim.long() + \\\n",
    "                                W * ylim.long() + \\\n",
    "                                xlim.long()\n",
    "\n",
    "                        voxel_grid.put_(index[mask], interp_weights[mask], accumulate=True)\n",
    "\n",
    "            if self.normalize:\n",
    "                mask = torch.nonzero(voxel_grid, as_tuple=True)\n",
    "                if mask[0].size()[0] > 0:\n",
    "                    mean = voxel_grid[mask].mean()\n",
    "                    std = voxel_grid[mask].std()\n",
    "                    if std > 0:\n",
    "                        voxel_grid[mask] = (voxel_grid[mask] - mean) / std\n",
    "                    else:\n",
    "                        voxel_grid[mask] = voxel_grid[mask] - mean\n",
    "\n",
    "        return voxel_grid\n",
    "\n",
    "def events_to_voxel_grid(bin, x, y, p, t, device: str='cpu'):\n",
    "    t = (t - t[0]).astype('float32')\n",
    "    t = (t/t[-1])\n",
    "    x = x.astype('float32')\n",
    "    y = y.astype('float32')\n",
    "    pol = p.astype('float32') # -1 1\n",
    "    return voxel_grid.convert(\n",
    "            torch.from_numpy(x),\n",
    "            torch.from_numpy(y),\n",
    "            torch.from_numpy(pol),\n",
    "        torch.from_numpy(t))\n",
    "\n",
    "def mvsecRectifyFrames(frames, x_map, y_map):\n",
    "    \"\"\"\n",
    "    Rectifies the spatial coordinates of input frames using mapping matrices (vectorized).\n",
    "    CAUTION: Ensure frames and maps correspond to the same side (e.g., DAVIS/left or DAVIS/right)!\n",
    "\n",
    "    :param frames: np.array of shape [N, H, W] containing frames (e.g., depth maps)\n",
    "    :param x_map: np.array of shape [H, W] containing rectified x-coordinates\n",
    "    :param y_map: np.array of shape [H, W] containing rectified y-coordinates\n",
    "    :return: rectified frames, np.array of shape [N, H, W] with invalid pixels marked as NaN\n",
    "    \"\"\"\n",
    "    print(\"\\nRectifying frame coordinates (vectorized)...\")\n",
    "    N, H, W = frames.shape\n",
    "    rectified_frames = np.full((N, H, W), np.nan, dtype=np.float32)  # Initialize with NaN\n",
    "    \n",
    "    # Validate map dimensions\n",
    "    if x_map.shape != (H, W) or y_map.shape != (H, W):\n",
    "        raise ValueError(f\"Expected x_map and y_map of shape ({H}, {W}), got {x_map.shape} and {y_map.shape}\")\n",
    "    \n",
    "    # Generate pixel coordinates\n",
    "    u, v = np.meshgrid(np.arange(W), np.arange(H))\n",
    "    u = u.ravel()  # Shape: [H*W]\n",
    "    v = v.ravel()  # Shape: [H*W]\n",
    "    \n",
    "    # Get rectified coordinates for all pixels (load maps once)\n",
    "    u_rect = x_map[v, u]  # Shape: [H*W]\n",
    "    v_rect = y_map[v, u]  # Shape: [H*W]\n",
    "    \n",
    "    # Filter valid mappings (non-NaN)\n",
    "    valid = (~np.isnan(u_rect) & ~np.isnan(v_rect))\n",
    "    u_valid = u[valid]\n",
    "    v_valid = v[valid]\n",
    "    u_rect_valid = u_rect[valid]\n",
    "    v_rect_valid = v_rect[valid]\n",
    "    \n",
    "    # Round rectified coordinates\n",
    "    u_rect_int = np.round(u_rect_valid).astype(int)\n",
    "    v_rect_int = np.round(v_rect_valid).astype(int)\n",
    "    \n",
    "    # Ensure rounded coordinates are within bounds\n",
    "    valid_bounds = (0 <= u_rect_int) & (u_rect_int < W) & (0 <= v_rect_int) & (v_rect_int < H)\n",
    "    if not np.all(valid_bounds):\n",
    "        print(f\"Warning: {np.sum(~valid_bounds)} out-of-bounds rectified coordinates detected\")\n",
    "        u_valid = u_valid[valid_bounds]\n",
    "        v_valid = v_valid[valid_bounds]\n",
    "        u_rect_int = u_rect_int[valid_bounds]\n",
    "        v_rect_int = v_rect_int[valid_bounds]\n",
    "    \n",
    "    # Process each frame\n",
    "    for i in tqdm(range(N), desc=\"Rectifying frames\"):\n",
    "        frame = frames[i]\n",
    "        \n",
    "        # Get values for valid pixels\n",
    "        values = frame[v_valid, u_valid]\n",
    "        valid_values = ~np.isnan(values)\n",
    "        u_rect_int_valid = u_rect_int[valid_values]\n",
    "        v_rect_int_valid = v_rect_int[valid_values]\n",
    "        values_valid = values[valid_values]\n",
    "        \n",
    "        # Handle occlusions: keep smallest depth (closest)\n",
    "        # Create a unique index for each rectified pixel\n",
    "        indices = v_rect_int_valid * W + u_rect_int_valid\n",
    "        sort_idx = np.argsort(values_valid)  # Sort by depth (ascending)\n",
    "        indices_sorted = indices[sort_idx]\n",
    "        values_sorted = values_valid[sort_idx]\n",
    "        u_rect_sorted = u_rect_int_valid[sort_idx]\n",
    "        v_rect_sorted = v_rect_int_valid[sort_idx]\n",
    "        \n",
    "        # Keep the first occurrence (smallest depth) for each unique index\n",
    "        _, unique_idx = np.unique(indices_sorted, return_index=True)\n",
    "        unique_u_rect = u_rect_sorted[unique_idx]\n",
    "        unique_v_rect = v_rect_sorted[unique_idx]\n",
    "        unique_values = values_sorted[unique_idx]\n",
    "        \n",
    "        # Assign values to rectified frame\n",
    "        rectified_frames[i, unique_v_rect, unique_u_rect] = unique_values\n",
    "    \n",
    "    return rectified_frames\n",
    "\n",
    "def post_process_frames(rectified_frames, inpaint_radius=10, max_iterations=3, use_interpolation=False):\n",
    "    \"\"\"\n",
    "    Post-process rectified frames to fill NaN regions using inpainting or interpolation.\n",
    "    \n",
    "    :param rectified_frames: np.array of shape [N, H, W] with NaN for invalid pixels\n",
    "    :param inpaint_radius: radius for inpainting neighborhood (larger for bigger holes)\n",
    "    :param max_iterations: number of inpainting iterations for large holes\n",
    "    :param use_interpolation: if True, use bilinear interpolation instead of inpainting\n",
    "    :return: processed frames with NaN regions filled\n",
    "    \"\"\"\n",
    "    processed_frames = rectified_frames.copy()\n",
    "    N, H, W = rectified_frames.shape\n",
    "    \n",
    "    if use_interpolation:\n",
    "        # Bilinear interpolation to fill NaN regions\n",
    "        for i in tqdm(range(N)):\n",
    "            frame = rectified_frames[i]\n",
    "            mask = np.isnan(frame)\n",
    "            if np.any(mask):\n",
    "                # Create a grid of valid coordinates\n",
    "                x, y = np.meshgrid(np.arange(W), np.arange(H))\n",
    "                valid = ~mask\n",
    "                points = np.stack([y[valid], x[valid]], axis=-1)\n",
    "                values = frame[valid]\n",
    "                from scipy.interpolate import griddata\n",
    "                # Interpolate NaN regions\n",
    "                interpolated = griddata(points, values, (y, x), method='linear', fill_value=0)\n",
    "                processed_frames[i] = np.where(mask, interpolated, frame)\n",
    "    else:\n",
    "        # Iterative inpainting with OpenCV (Telea method)\n",
    "        for i in tqdm(range(N)):\n",
    "            frame = rectified_frames[i]\n",
    "            for _ in range(max_iterations):\n",
    "                mask = np.isnan(frame).astype(np.uint8)\n",
    "                if not np.any(mask):\n",
    "                    break\n",
    "                frame_inp = np.where(np.isnan(frame), 0, frame)\n",
    "                frame = cv2.inpaint(frame_inp, mask, inpaintRadius=inpaint_radius, flags=cv2.INPAINT_TELEA)\n",
    "            processed_frames[i] = frame\n",
    "    \n",
    "    return processed_frames\n",
    "\n",
    "# Example usage\n",
    "# rectified_frames = mvsecRectifyFrames(frames, x_map, y_map)\n",
    "# rectified_frames_filled = post_process_frames(rectified_frames)\n",
    "\n",
    "def mvsecLoadRectificationMaps(Lx_path, Ly_path, Rx_path, Ry_path):\n",
    "    \"\"\"\n",
    "    Loads the rectification maps for further calibration of DAVIS' spike events coordinates.\n",
    "\n",
    "    :param Lx_path: path of the .txt file containing the mapping of the x coordinate for the left DAVIS camera\n",
    "    :param Ly_path:                     ..                              y        ..          left\n",
    "    :param Rx_path:                     ..                              x        ..          right\n",
    "    :param Ry_path:                     ..                              y        ..          right\n",
    "    :return: all corresponding mapping matrices in the form of a numpy array\n",
    "    \"\"\"\n",
    "    print(\"\\nloading rectification maps...\")\n",
    "    Lx_map = np.loadtxt(Lx_path)\n",
    "    Ly_map = np.loadtxt(Ly_path)\n",
    "    Rx_map = np.loadtxt(Rx_path)\n",
    "    Ry_map = np.loadtxt(Ry_path)\n",
    "    return Lx_map, Ly_map, Rx_map, Ry_map\n",
    "\n",
    "\n",
    "def mvsecRectifyEvents(events, x_map, y_map):\n",
    "    \"\"\"\n",
    "    Rectifies the spatial coordinates of the input spike events in accordance to the given mapping matrices.\n",
    "    CAUTION: make sure events and maps correspond to the same side (DAVIS/left or DAVIS/right) !\n",
    "\n",
    "    :param events: a list of spike events to the format [X, Y, TIME, POLARITY]\n",
    "    :param x_map: np.array obtained by mvsecLoadRectificationMaps() function\n",
    "    :param y_map:                       ..\n",
    "    :return: rectified events, in the same format as the input events\n",
    "    \"\"\"\n",
    "    # print(\"\\nrectifying spike coordinates...\")\n",
    "    rect_events = []\n",
    "    for event in tqdm(events):\n",
    "        x = int(event[0])\n",
    "        y = int(event[1])\n",
    "        x_rect = x_map[y, x]\n",
    "        y_rect = y_map[y, x]\n",
    "        rect_events.append([x_rect, y_rect, event[2], event[3]])\n",
    "\n",
    "    # convert to np.array and remove spikes falling outside of the Lidar field of view (fov)\n",
    "    rect_events = np.array(rect_events)\n",
    "    rect_events = rect_events[(rect_events[:, 0] >= 0)\n",
    "                              & (rect_events[:, 0] <= 346)\n",
    "                              & (rect_events[:, 1] >= 0)\n",
    "                              & (rect_events[:, 1] <= 260)]\n",
    "    return rect_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/mnt/sdc/lxy/datasets/MVSEC/OpenDataLab___MVSEC/raw/MVSEC/hdf5/'\n",
    "scenario = 'outdoor_night'\n",
    "# scenario = 'indoor_flying'\n",
    "# scenario = 'outdoor_day'\n",
    "split = '3'\n",
    "save_root = '/mnt/sdc/lxy/datasets/MVSEC/processed_rect_odem/' + f'{scenario}/{scenario}{split}/'\n",
    "timestamp_root = save_root + 'index_It_left.txt'\n",
    "data_path = root_dir + f'{scenario}/{scenario}{split}_data.hdf5'\n",
    "gt_path = root_dir + f'{scenario}/{scenario}{split}_gt.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data keys: ['events', 'image_raw', 'image_raw_event_inds', 'image_raw_ts', 'imu', 'imu_ts']\n",
      "GT keys: ['blended_image_rect', 'blended_image_rect_ts', 'depth_image_raw', 'depth_image_raw_ts', 'depth_image_rect', 'depth_image_rect_ts', 'flow_dist', 'flow_dist_ts', 'odometry', 'odometry_ts', 'pose', 'pose_ts']\n",
      "\n",
      "loading rectification maps...\n",
      "Image raw: (2854, 260, 346)\n",
      "Image raw timestamps: (2854,)\n",
      "Image raw event indices: (2854,)\n",
      "Blended image rect: (5429, 260, 346, 3)\n",
      "Blended image rect timestamps: (5429,)\n",
      "Pose timestamps: (4570,)\n",
      "Pose: (4570, 4, 4)\n",
      "Delta t image: 0.11956906318664551 0.09441089630126953 0.09692168516972986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103075060/103075060 [02:29<00:00, 689193.71it/s] \n"
     ]
    }
   ],
   "source": [
    "with h5py.File(data_path, 'r') as data, h5py.File(gt_path, 'r') as gt:\n",
    "    data = data['davis']['left']\n",
    "    gt = gt['davis']['left']\n",
    "\n",
    "    print(f\"Data keys: {list(data.keys())}\")\n",
    "    print(f\"GT keys: {list(gt.keys())}\")\n",
    "    image_raw = data['image_raw'][:]\n",
    "    image_raw_ts = data['image_raw_ts'][:]\n",
    "    image_raw_event_inds = data['image_raw_event_inds'][:]\n",
    "    blended_image_rect = gt['blended_image_rect'][:]\n",
    "    blended_image_rect_ts = gt['blended_image_rect_ts'][:]\n",
    "    # depth_image_rect = gt['depth_image_rect'][:]\n",
    "    # depth_image_rect_ts = gt['depth_image_rect_ts'][:]\n",
    "    pose_ts = gt['pose_ts'][:]\n",
    "    pose = gt['pose'][:]\n",
    "    Levents = data['events'][:]\n",
    "    # remove events occurring during take-off and landing of the drone as well\n",
    "    # Levents = Levents[(Levents[:, 2] > depth_image_rect_ts[0] - 0.05) & (Levents[:, 2] < depth_image_rect_ts[-1])]\n",
    "    # rectify the spatial coordinates of spike events and get rid of events falling outside of the 346x260 fov\n",
    "    Lx_path = root_dir + '{}/{}_calib/{}_left_x_map.txt'.format(scenario, scenario, scenario)\n",
    "    Ly_path = root_dir + '{}/{}_calib/{}_left_y_map.txt'.format(scenario, scenario, scenario)\n",
    "    Rx_path = root_dir + '{}/{}_calib/{}_right_x_map.txt'.format(scenario, scenario, scenario)\n",
    "    Ry_path = root_dir + '{}/{}_calib/{}_right_y_map.txt'.format(scenario, scenario, scenario)\n",
    "    Lx_map, Ly_map, Rx_map, Ry_map = mvsecLoadRectificationMaps(Lx_path, Ly_path, Rx_path, Ry_path) \n",
    "    print(f\"Image raw: {image_raw.shape}\")\n",
    "    print(f\"Image raw timestamps: {image_raw_ts.shape}\")\n",
    "    print(f\"Image raw event indices: {image_raw_event_inds.shape}\")\n",
    "    # print(f\"Depth image rect: {depth_image_rect.shape}\")\n",
    "    # print(f\"Depth image rect timestamps: {depth_image_rect_ts.shape}\")\n",
    "    print(f\"Blended image rect: {blended_image_rect.shape}\")\n",
    "    print(f\"Blended image rect timestamps: {blended_image_rect_ts.shape}\")\n",
    "    print(f\"Pose timestamps: {pose_ts.shape}\")\n",
    "    print(f\"Pose: {pose.shape}\")\n",
    "\n",
    "with open(timestamp_root, 'r') as f:\n",
    "    # the save format is f.write(f\"{img_indices[j]}\\t{np.where(depth_image_rect_ts==filtered_depth_ts[j])[0][0]}\\t{filtered_image_ts[j]:.18e}\\t{filtered_depth_ts[j]:.18e}\\n\")\n",
    "    lines = f.readlines()\n",
    "    # Extract the first column from each line\n",
    "    img_indices = [int(line.split('\\t')[0]) for line in lines]\n",
    "    image_timestamps = [float(line.split()[1]) for line in lines]\n",
    "\n",
    "# check if any duplicate indices\n",
    "unique_indices, counts = np.unique(img_indices, return_counts=True)\n",
    "for i in range(len(counts)):\n",
    "    if counts[i] > 1:\n",
    "        print(f\"Duplicate index {unique_indices[i]} found {counts[i]} times\")\n",
    "# check delta t\n",
    "delta_t_img = np.diff(image_timestamps)\n",
    "print('Delta t image:', delta_t_img.max(), delta_t_img.min(), delta_t_img.mean())\n",
    "\n",
    "voxel_grid = VoxelGrid(channels=5, height=260, width=346, normalize=True)\n",
    "\n",
    "event_root = save_root + 'event_left/event_voxel_left/'\n",
    "event50_root = save_root + 'event_left/event50_voxel_left/'\n",
    "event_stream_root = save_root + 'event_left/event_stream_left/'\n",
    "event_template = '_event.hdf5'\n",
    "os.makedirs(event_root, exist_ok=True)\n",
    "os.makedirs(event50_root, exist_ok=True)\n",
    "os.makedirs(event_stream_root, exist_ok=True)\n",
    "\n",
    "event_stream_path = save_root + 'event_left/' + 'all' + event_template \n",
    "Lrect_events = np.array(mvsecRectifyEvents(Levents, Lx_map, Ly_map)) \n",
    "with h5py.File(event_stream_path, 'w') as f: \n",
    "    f.create_dataset('event_stream', data=Lrect_events) \n",
    "\n",
    "# with h5py.File(event_stream_path, 'r') as f: \n",
    "#     Lrect_events = f['event_stream'][:]\n",
    "\n",
    "event_indices = image_raw_event_inds[img_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2798/2798 [00:00<00:00, 21613.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# 预计算时间窗口索引并保存到文件\n",
    "time_windows = []\n",
    "output_file = save_root + \"event_windows_indices.txt\"  # 指定输出文件路径\n",
    "with open(output_file, 'w') as f:\n",
    "    for i in tqdm(range(len(event_indices) - 1)):\n",
    "        start_ts = Levents[event_indices[i], 2]\n",
    "        end_ts = start_ts + 0.05\n",
    "        start_idx = np.searchsorted(Lrect_events[:, 2], start_ts, side='right')\n",
    "        end_idx = np.searchsorted(Lrect_events[:, 2], end_ts, side='left')\n",
    "        time_windows.append((start_idx, end_idx))\n",
    "        # 写入到文件，每行格式为 \"start_idx end_idx\"\n",
    "        f.write(f\"{start_idx} {end_idx}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1504916639.9996707)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Levents[event_indices[0], 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1504916648.530176)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lrect_events[time_windows[88][0],2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event_chunk(i):\n",
    "    try:\n",
    "        start_idx, end_idx = time_windows[i]\n",
    "        rect_events = Lrect_events[start_idx:end_idx]\n",
    "        event_x = rect_events[:, 0]\n",
    "        event_y = rect_events[:, 1]\n",
    "        event_t = rect_events[:, 2]\n",
    "        event_p = rect_events[:, 3]\n",
    "        event_representation = events_to_voxel_grid(bin=5, x=event_x, y=event_y, p=event_p, t=event_t)\n",
    "        event_filename = event50_root + f'{i:06d}_{i+1:06d}' + event_template\n",
    "        with h5py.File(event_filename, 'w') as f:\n",
    "            f.create_dataset('event_voxels', data=event_representation.cpu().numpy())\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk {i}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2798/2798 [00:23<00:00, 117.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(event_indices)-1)):\n",
    "    process_event_chunk(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monst3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
